# Dockerfile for Jetson Orin/Xavier (JP6 R36.4.x)
# Base: JetPack runtime with CUDA/TensorRT from the host image
FROM nvcr.io/nvidia/l4t-jetpack:r36.4.0

# ---- Env -----------------------------------------------------------
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}
WORKDIR /workspace

# ---- System deps (Python 3.10) -------------------------------------
RUN apt-get update && apt-get install -y \
    python3 python3-pip python3-dev python3-venv python3-distutils \
    build-essential cmake git wget curl pkg-config \
    libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev \
    libgomp1 libboost-all-dev libssl-dev libffi-dev \
 && rm -rf /var/lib/apt/lists/*

# ---- Python deps ----------------------------------------------------
# Usa siempre python3 / pip3 (3.10 en JP6)
COPY requirements_jetson.txt /workspace/
RUN python3 -m pip install --upgrade pip setuptools wheel \
 && python3 -m pip install --no-cache-dir -r /workspace/requirements_jetson.txt \
 && python3 -m pip install --no-cache-dir onnx onnxruntime \
 && python3 -m pip install --no-cache-dir \
      plotly==5.17.0 \
      kaleido==0.2.1 \
      psutil==5.9.5 \
      tqdm==4.66.1

# ---- (Opcional) PyCUDA ---------------------------------------------
# Si realmente necesitas PyCUDA, compÃ­lalo contra CUDA del sistema.
# Omitir si no lo usas; compilar en Orin puede tardar.
RUN git clone https://github.com/inducer/pycuda.git /tmp/pycuda && \
    cd /tmp/pycuda && \
    python3 configure.py --cuda-root=/usr/local/cuda --cudadrv-lib-dir=/usr/lib/aarch64-linux-gnu && \
    python3 -m pip install . && \
    cd / && rm -rf /tmp/pycuda

# ---- Directorios de trabajo ----------------------------------------
RUN mkdir -p /workspace/models /workspace/results /workspace/exported_models /workspace/data

# ---- Info/health script (sin nvidia-smi en Jetson) -----------------
RUN echo '#!/bin/bash\n\
echo "=== Jetson System Information ==="\n\
echo "Arch: $(uname -m)"; echo "Kernel: $(uname -r)"; echo "CUDA: $(nvcc --version 2>/dev/null | grep release || echo N/A)";\n\
python3 --version\n\
echo "=== Python Packages (key) ==="\n\
python3 - <<PY\n\
import importlib, pkgutil\n\
mods = ["torch","tensorrt","onnx","onnxruntime","pycuda","plotly"]\n\
for m in mods:\n\
    spec = importlib.util.find_spec(m)\n\
    print(f"{m}:","OK" if spec else "missing")\n\
PY\n\
echo "CUDA visible? (Torch)"\n\
python3 - <<PY\n\
try:\n\
    import torch\n\
    print("torch.cuda.is_available():", torch.cuda.is_available())\n\
    print("device_count:", torch.cuda.device_count())\n\
except Exception as e:\n\
    print("torch not installed or failed:", e)\n\
PY\n\
' > /workspace/check_system.sh && chmod +x /workspace/check_system.sh

# ---- Entrypoint -----------------------------------------------------
RUN echo '#!/bin/bash\n\
echo "=== Jetson Benchmarking Container ==="\n\
echo "Container started. Common commands:"\n\
echo "  - python3 export_models.py --model_path /workspace/models/model.pt --output_dir /workspace/models"\n\
echo "  - trtexec --onnx=/workspace/models/model.onnx --saveEngine=/workspace/models/model.engine --fp16"\n\
echo "  - python3 benchmark_models_plotly_jetson.py --onnx_path /workspace/models/model.onnx --tensorrt_path /workspace/models/model.engine --output_dir /workspace/results --num_runs 100 --batch_size 1"\n\
echo "  - ./check_system.sh"\n\
exec "$@"\n\
' > /workspace/entrypoint.sh && chmod +x /workspace/entrypoint.sh

ENTRYPOINT ["/workspace/entrypoint.sh"]
CMD ["bash"]

